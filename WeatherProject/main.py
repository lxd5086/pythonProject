# -*- coding: utf-8 -*-
"""
æµ¦ä¸œæ–°åŒºå¤©æ°”é¢„æŠ¥çˆ¬å–é¡¹ç›® - ä¸»ç¨‹åº
"""

import os
import sys
import time
import argparse
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from web_scraper import WeatherScraper
from data_processor import WeatherDataProcessor
from visualizer import WeatherVisualizer
from config import DATA_FILES, LOG_CONFIG

import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
	level=getattr(logging, LOG_CONFIG['level']),
	format=LOG_CONFIG['format'],
	handlers=[
		logging.FileHandler(LOG_CONFIG['file'], encoding='utf-8'),
		logging.StreamHandler(sys.stdout)
	]
)

logger = logging.getLogger(__name__)


class WeatherProjectManager:
	"""å¤©æ°”é¡¹ç›®ç®¡ç†å™¨"""

	def __init__(self):
		self.scraper = WeatherScraper()
		self.processor = WeatherDataProcessor()
		self.visualizer = WeatherVisualizer()

	def run_scraping(self):
		"""æ‰§è¡Œæ•°æ®çˆ¬å–"""
		print("ğŸŒ¤ï¸  å¼€å§‹çˆ¬å–æµ¦ä¸œæ–°åŒºå¤©æ°”æ•°æ®...")
		logger.info("å¼€å§‹æ•°æ®çˆ¬å–æµç¨‹")

		try:
			# çˆ¬å–æ•°æ®
			weather_data = self.scraper.scrape_all_sources()

			if weather_data:
				print(f"âœ“ çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(weather_data)} æ¡æ•°æ®")

				# ä¿å­˜åŸå§‹æ•°æ®
				self.scraper.save_to_csv(weather_data)
				self.scraper.save_to_json(weather_data)

				logger.info(f"æ•°æ®çˆ¬å–æˆåŠŸï¼Œè·å– {len(weather_data)} æ¡è®°å½•")
				return True
			else:
				print("âœ— æœªè·å–åˆ°ä»»ä½•æ•°æ®")
				logger.warning("æ•°æ®çˆ¬å–å¤±è´¥ï¼Œæœªè·å–åˆ°æ•°æ®")
				return False

		except Exception as e:
			print(f"âœ— æ•°æ®çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
			logger.error(f"æ•°æ®çˆ¬å–å¼‚å¸¸: {e}")
			return False

	def run_processing(self):
		"""æ‰§è¡Œæ•°æ®å¤„ç†"""
		print("ğŸ“Š å¼€å§‹å¤„ç†å¤©æ°”æ•°æ®...")
		logger.info("å¼€å§‹æ•°æ®å¤„ç†æµç¨‹")

		try:
			# æ£€æŸ¥åŸå§‹æ•°æ®æ˜¯å¦å­˜åœ¨
			if not os.path.exists(DATA_FILES['weather_data']):
				print("âœ— æœªæ‰¾åˆ°åŸå§‹æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®çˆ¬å–")
				return False

			# åŠ è½½å¹¶å¤„ç†æ•°æ®
			df = self.processor.load_csv_data()

			if df.empty:
				print("âœ— åŸå§‹æ•°æ®ä¸ºç©º")
				return False

			print(f"âœ“ åŠ è½½äº† {len(df)} æ¡åŸå§‹æ•°æ®")

			# æ•°æ®æ¸…æ´—å’Œå¤„ç†
			processed_df = self.processor.process_dataframe(df)

			# ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
			stats = self.processor.aggregate_data(processed_df)

			# ä¿å­˜å¤„ç†åçš„æ•°æ®
			result = self.processor.save_processed_data(processed_df, stats)

			if result:
				print("âœ“ æ•°æ®å¤„ç†å®Œæˆ")
				print(f"  - å¤„ç†åæ•°æ®: {len(result['processed_data'])} æ¡")
				print(f"  - æ•°æ®æ¥æº: {list(stats.get('data_sources', {}).keys())}")

				# æ˜¾ç¤ºå¤©æ°”æ‘˜è¦
				if 'summary' in result:
					print(f"\nğŸ“‹ å¤©æ°”é¢„æŠ¥æ‘˜è¦:")
					print(result['summary'])

				logger.info("æ•°æ®å¤„ç†æˆåŠŸå®Œæˆ")
				return True
			else:
				print("âœ— æ•°æ®å¤„ç†å¤±è´¥")
				return False

		except Exception as e:
			print(f"âœ— æ•°æ®å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
			logger.error(f"æ•°æ®å¤„ç†å¼‚å¸¸: {e}")
			return False

	def run_visualization(self):
		"""æ‰§è¡Œæ•°æ®å¯è§†åŒ–"""
		print("ğŸ“ˆ å¼€å§‹ç”Ÿæˆæ•°æ®å¯è§†åŒ–å›¾è¡¨...")
		logger.info("å¼€å§‹æ•°æ®å¯è§†åŒ–æµç¨‹")

		try:
			# æ£€æŸ¥å¤„ç†åçš„æ•°æ®æ˜¯å¦å­˜åœ¨
			if not os.path.exists(DATA_FILES['processed_data']):
				print("âœ— æœªæ‰¾åˆ°å¤„ç†åçš„æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œæ•°æ®å¤„ç†")
				return False

			# ç”Ÿæˆå›¾è¡¨
			charts_generated = self.visualizer.generate_all_charts()

			if charts_generated:
				print(f"âœ“ å¯è§†åŒ–å®Œæˆï¼Œç”Ÿæˆäº† {len(charts_generated)} ä¸ªå›¾è¡¨:")
				for chart in charts_generated:
					print(f"  - {chart}")
				print(f"\nğŸ“ å›¾è¡¨ä¿å­˜ä½ç½®: {DATA_FILES['charts']}")

				logger.info(f"æ•°æ®å¯è§†åŒ–æˆåŠŸï¼Œç”Ÿæˆ {len(charts_generated)} ä¸ªå›¾è¡¨")
				return True
			else:
				print("âœ— æœªç”Ÿæˆä»»ä½•å›¾è¡¨")
				return False

		except Exception as e:
			print(f"âœ— æ•°æ®å¯è§†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
			logger.error(f"æ•°æ®å¯è§†åŒ–å¼‚å¸¸: {e}")
			return False

	def run_full_pipeline(self):
		"""æ‰§è¡Œå®Œæ•´æµç¨‹"""
		print("ğŸš€ å¼€å§‹æ‰§è¡Œå®Œæ•´çš„å¤©æ°”æ•°æ®åˆ†ææµç¨‹...")
		print("=" * 60)

		start_time = time.time()
		logger.info("å¼€å§‹å®Œæ•´æ•°æ®å¤„ç†æµç¨‹")

		# æ­¥éª¤1: æ•°æ®çˆ¬å–
		print("\nã€æ­¥éª¤ 1/3ã€‘æ•°æ®çˆ¬å–")
		scraping_success = self.run_scraping()

		if not scraping_success:
			print("âŒ æµç¨‹ç»ˆæ­¢ï¼šæ•°æ®çˆ¬å–å¤±è´¥")
			return False

		print("\n" + "-" * 40)

		# æ­¥éª¤2: æ•°æ®å¤„ç†
		print("\nã€æ­¥éª¤ 2/3ã€‘æ•°æ®å¤„ç†")
		processing_success = self.run_processing()

		if not processing_success:
			print("âŒ æµç¨‹ç»ˆæ­¢ï¼šæ•°æ®å¤„ç†å¤±è´¥")
			return False

		print("\n" + "-" * 40)

		# æ­¥éª¤3: æ•°æ®å¯è§†åŒ–
		print("\nã€æ­¥éª¤ 3/3ã€‘æ•°æ®å¯è§†åŒ–")
		visualization_success = self.run_visualization()

		# å®Œæˆæ€»ç»“
		end_time = time.time()
		duration = end_time - start_time

		print("\n" + "=" * 60)

		if scraping_success and processing_success and visualization_success:
			print("ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
			print(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f} ç§’")
			print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {DATA_FILES['weather_data']}")
			print(f"ğŸ“ˆ å›¾è¡¨ç›®å½•: {DATA_FILES['charts']}")
			logger.info(f"å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶ {duration:.2f} ç§’")

			# æ˜¾ç¤ºé¡¹ç›®æ–‡ä»¶ç»“æ„
			self.show_project_structure()

			return True
		else:
			print("âŒ æµç¨‹ç»ˆæ­¢")
			logger.error("å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥")
			return False

	def show_project_structure(self):
		"""æ˜¾ç¤ºé¡¹ç›®æ–‡ä»¶ç»“æ„"""
		print(f"\nğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„:")
		print("WeatherProject/")
		print("â”œâ”€â”€ config.py          # é…ç½®æ–‡ä»¶")
		print("â”œâ”€â”€ web_scraper.py     # æ•°æ®çˆ¬å–æ¨¡å—")
		print("â”œâ”€â”€ data_processor.py  # æ•°æ®å¤„ç†æ¨¡å—")
		print("â”œâ”€â”€ visualizer.py      # æ•°æ®å¯è§†åŒ–æ¨¡å—")
		print("â”œâ”€â”€ main.py           # ä¸»ç¨‹åºå…¥å£")
		print("â”œâ”€â”€ utils.py          # å·¥å…·å‡½æ•°")
		print("â”œâ”€â”€ data/             # æ•°æ®ç›®å½•")

		# æ£€æŸ¥æ•°æ®æ–‡ä»¶
		data_files = [
			("weather_data.csv", "åŸå§‹å¤©æ°”æ•°æ®"),
			("processed_weather.json", "å¤„ç†åæ•°æ®"),
		]

		for filename, description in data_files:
			filepath = os.path.join("data", filename)
			if os.path.exists(filepath):
				size = os.path.getsize(filepath)
				print(f"â”‚   â”œâ”€â”€ {filename:<20} # {description} ({size} bytes)")
			else:
				print(f"â”‚   â”œâ”€â”€ {filename:<20} # {description} (ä¸å­˜åœ¨)")

		print("â”‚   â””â”€â”€ charts/        # å›¾è¡¨ç›®å½•")

		# æ£€æŸ¥å›¾è¡¨æ–‡ä»¶
		charts_dir = DATA_FILES['charts']
		if os.path.exists(charts_dir):
			chart_files = [f for f in os.listdir(charts_dir) if f.endswith('.png')]
			for chart_file in chart_files:
				print(f"â”‚       â”œâ”€â”€ {chart_file}")

		print("â””â”€â”€ logs/             # æ—¥å¿—ç›®å½•")

	def show_status(self):
		"""æ˜¾ç¤ºé¡¹ç›®çŠ¶æ€"""
		print("ğŸ“Š é¡¹ç›®çŠ¶æ€æ£€æŸ¥")
		print("-" * 30)

		# æ£€æŸ¥æ•°æ®æ–‡ä»¶
		files_to_check = [
			(DATA_FILES['weather_data'], "åŸå§‹æ•°æ®"),
			(DATA_FILES['processed_data'], "å¤„ç†åæ•°æ®"),
		]

		for filepath, description in files_to_check:
			if os.path.exists(filepath):
				size = os.path.getsize(filepath)
				mtime = datetime.fromtimestamp(os.path.getmtime(filepath))
				print(f"âœ“ {description}: {size} bytes, æ›´æ–°äº {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
			else:
				print(f"âœ— {description}: æ–‡ä»¶ä¸å­˜åœ¨")

		# æ£€æŸ¥å›¾è¡¨æ–‡ä»¶
		charts_dir = DATA_FILES['charts']
		if os.path.exists(charts_dir):
			chart_files = [f for f in os.listdir(charts_dir) if f.endswith('.png')]
			print(f"âœ“ å¯è§†åŒ–å›¾è¡¨: {len(chart_files)} ä¸ªæ–‡ä»¶")
		else:
			print("âœ— å¯è§†åŒ–å›¾è¡¨: ç›®å½•ä¸å­˜åœ¨")


def create_argument_parser():
	"""åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
	parser = argparse.ArgumentParser(
		description='æµ¦ä¸œæ–°åŒºå¤©æ°”é¢„æŠ¥æ•°æ®é‡‡é›†ä¸åˆ†æé¡¹ç›®',
		formatter_class=argparse.RawDescriptionHelpFormatter,
		epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python main.py --full              # æ‰§è¡Œå®Œæ•´æµç¨‹
  python main.py --scrape           # ä»…æ‰§è¡Œæ•°æ®çˆ¬å–
  python main.py --process          # ä»…æ‰§è¡Œæ•°æ®å¤„ç†
  python main.py --visualize        # ä»…æ‰§è¡Œæ•°æ®å¯è§†åŒ–
  python main.py --status           # æŸ¥çœ‹é¡¹ç›®çŠ¶æ€
        """
	)

	parser.add_argument('--full', action='store_true',
						help='æ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆçˆ¬å–â†’å¤„ç†â†’å¯è§†åŒ–ï¼‰')
	parser.add_argument('--scrape', action='store_true',
						help='ä»…æ‰§è¡Œæ•°æ®çˆ¬å–')
	parser.add_argument('--process', action='store_true',
						help='ä»…æ‰§è¡Œæ•°æ®å¤„ç†')
	parser.add_argument('--visualize', action='store_true',
						help='ä»…æ‰§è¡Œæ•°æ®å¯è§†åŒ–')
	parser.add_argument('--status', action='store_true',
						help='æŸ¥çœ‹é¡¹ç›®çŠ¶æ€')

	return parser


def main():
	"""ä¸»å‡½æ•°"""
	# æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯
	print("ğŸŒ¤ï¸  æµ¦ä¸œæ–°åŒºå¤©æ°”é¢„æŠ¥æ•°æ®é‡‡é›†ä¸åˆ†æé¡¹ç›®")
	print("=" * 50)
	print(f"å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
	print()

	# è§£æå‘½ä»¤è¡Œå‚æ•°
	parser = create_argument_parser()
	args = parser.parse_args()

	# åˆ›å»ºé¡¹ç›®ç®¡ç†å™¨å®ä¾‹
	manager = WeatherProjectManager()

	# æ ¹æ®å‚æ•°é€‰æ‹©æ‰§è¡Œæ¨¡å¼
	if args.full:
		manager.run_full_pipeline()
	elif args.scrape:
		manager.run_scraping()
	elif args.process:
		manager.run_processing()
	elif args.visualize:
		manager.run_visualization()
	elif args.status:
		manager.show_status()
	else:
		print("â— è¯·ä½¿ç”¨ --full, --scrape, --process, --visualize æˆ– --status æŒ‡å®šæ“ä½œæ¨¡å¼")
		parser.print_help()

	# è®°å½•ç»“æŸæ—¶é—´
	end_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
	print(f"\nç»“æŸæ—¶é—´: {end_time}")
	logger.info(f"ç¨‹åºç»“æŸï¼Œç»“æŸæ—¶é—´: {end_time}")


if __name__ == "__main__":
	main()